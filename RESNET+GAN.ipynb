{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkk6JW45kYCp1AUNMJaU02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RummanAli/FYP2022-KnowledgeVision/blob/main/RESNET%2BGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wonf5qZ6E_4K"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Add, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWGwykqSC7VS",
        "outputId": "1b7690e1-1af8-47a4-d7ff-7cb09dd447be"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CO3-HW2IOaN"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04hruONPMaHn"
      },
      "source": [
        "x_train = x_train.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JeYA3hrpiT3"
      },
      "source": [
        "x_train  = np.expand_dims(x_train, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZmeU0TNp5px",
        "outputId": "ff2b45aa-3499-4248-aefb-864acceb6bf6"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw3cZvUzHt8M"
      },
      "source": [
        "input = Input(x_train.shape[1:])\n",
        "f1 = Flatten()(input)\n",
        "d1 = Dense(32, activation='relu')(f1)\n",
        "d2 = Dense(64, activation='relu')(d1)\n",
        "d3 = Dense(32, activation='relu')(d2)\n",
        "added = Add()([d1, d3])\n",
        "out = Dense(10, activation='softmax')(added)\n",
        "model = Model(inputs=input, outputs=out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrIfDvpdDhn0",
        "outputId": "ef6b8e15-5217-4ecd-b865-e8f0ae28a71d"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 784)          0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 32)           25120       flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 64)           2112        dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 32)           2080        dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32)           0           dense_16[0][0]                   \n",
            "                                                                 dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 10)           330         add_3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 29,642\n",
            "Trainable params: 29,642\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN3ysMGMFIN2",
        "outputId": "72a59a49-38d3-487a-9933-58d9c95773a9"
      },
      "source": [
        "model.fit(x = x_train,y = y_train,epochs = 200,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2438 - accuracy: 0.9431 - val_loss: 0.4038 - val_accuracy: 0.9268\n",
            "Epoch 2/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2568 - accuracy: 0.9387 - val_loss: 0.4025 - val_accuracy: 0.9286\n",
            "Epoch 3/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2492 - accuracy: 0.9427 - val_loss: 0.3994 - val_accuracy: 0.9301\n",
            "Epoch 4/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2437 - accuracy: 0.9434 - val_loss: 0.3948 - val_accuracy: 0.9317\n",
            "Epoch 5/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2561 - accuracy: 0.9415 - val_loss: 0.4158 - val_accuracy: 0.9270\n",
            "Epoch 6/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.9401 - val_loss: 0.4165 - val_accuracy: 0.9307\n",
            "Epoch 7/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2568 - accuracy: 0.9408 - val_loss: 0.4299 - val_accuracy: 0.9289\n",
            "Epoch 8/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2572 - accuracy: 0.9384 - val_loss: 0.4522 - val_accuracy: 0.9244\n",
            "Epoch 9/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2583 - accuracy: 0.9380 - val_loss: 0.4828 - val_accuracy: 0.9302\n",
            "Epoch 10/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2682 - accuracy: 0.9376 - val_loss: 0.4938 - val_accuracy: 0.9220\n",
            "Epoch 11/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2540 - accuracy: 0.9399 - val_loss: 0.4298 - val_accuracy: 0.9287\n",
            "Epoch 12/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2459 - accuracy: 0.9439 - val_loss: 0.4505 - val_accuracy: 0.9239\n",
            "Epoch 13/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.9420 - val_loss: 0.4536 - val_accuracy: 0.9225\n",
            "Epoch 14/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2489 - accuracy: 0.9415 - val_loss: 0.4467 - val_accuracy: 0.9298\n",
            "Epoch 15/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2618 - accuracy: 0.9402 - val_loss: 0.4673 - val_accuracy: 0.9266\n",
            "Epoch 16/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2634 - accuracy: 0.9388 - val_loss: 0.4423 - val_accuracy: 0.9272\n",
            "Epoch 17/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2593 - accuracy: 0.9398 - val_loss: 0.4427 - val_accuracy: 0.9272\n",
            "Epoch 18/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2840 - accuracy: 0.9345 - val_loss: 0.6721 - val_accuracy: 0.9138\n",
            "Epoch 19/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2767 - accuracy: 0.9380 - val_loss: 0.4613 - val_accuracy: 0.9297\n",
            "Epoch 20/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2573 - accuracy: 0.9416 - val_loss: 0.4545 - val_accuracy: 0.9289\n",
            "Epoch 21/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2605 - accuracy: 0.9397 - val_loss: 0.4097 - val_accuracy: 0.9281\n",
            "Epoch 22/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2703 - accuracy: 0.9380 - val_loss: 0.4564 - val_accuracy: 0.9253\n",
            "Epoch 23/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2668 - accuracy: 0.9369 - val_loss: 0.4375 - val_accuracy: 0.9329\n",
            "Epoch 24/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2663 - accuracy: 0.9389 - val_loss: 0.4367 - val_accuracy: 0.9227\n",
            "Epoch 25/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2726 - accuracy: 0.9369 - val_loss: 0.4811 - val_accuracy: 0.9285\n",
            "Epoch 26/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2685 - accuracy: 0.9367 - val_loss: 0.4814 - val_accuracy: 0.9259\n",
            "Epoch 27/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2885 - accuracy: 0.9319 - val_loss: 0.5100 - val_accuracy: 0.9228\n",
            "Epoch 28/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.9358 - val_loss: 0.4971 - val_accuracy: 0.9251\n",
            "Epoch 29/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2624 - accuracy: 0.9387 - val_loss: 0.5141 - val_accuracy: 0.9202\n",
            "Epoch 30/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2737 - accuracy: 0.9365 - val_loss: 0.4721 - val_accuracy: 0.9238\n",
            "Epoch 31/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2768 - accuracy: 0.9348 - val_loss: 0.4898 - val_accuracy: 0.9247\n",
            "Epoch 32/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2820 - accuracy: 0.9345 - val_loss: 0.4785 - val_accuracy: 0.9221\n",
            "Epoch 33/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2875 - accuracy: 0.9344 - val_loss: 0.5388 - val_accuracy: 0.9285\n",
            "Epoch 34/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2797 - accuracy: 0.9340 - val_loss: 0.4697 - val_accuracy: 0.9283\n",
            "Epoch 35/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2721 - accuracy: 0.9371 - val_loss: 0.5091 - val_accuracy: 0.9252\n",
            "Epoch 36/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2704 - accuracy: 0.9376 - val_loss: 0.5125 - val_accuracy: 0.9135\n",
            "Epoch 37/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2694 - accuracy: 0.9387 - val_loss: 0.4637 - val_accuracy: 0.9297\n",
            "Epoch 38/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2601 - accuracy: 0.9405 - val_loss: 0.5171 - val_accuracy: 0.9251\n",
            "Epoch 39/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.9395 - val_loss: 0.5152 - val_accuracy: 0.9215\n",
            "Epoch 40/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2659 - accuracy: 0.9390 - val_loss: 0.4947 - val_accuracy: 0.9244\n",
            "Epoch 41/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2747 - accuracy: 0.9367 - val_loss: 0.5314 - val_accuracy: 0.9244\n",
            "Epoch 42/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2692 - accuracy: 0.9390 - val_loss: 0.5249 - val_accuracy: 0.9212\n",
            "Epoch 43/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2719 - accuracy: 0.9360 - val_loss: 0.5457 - val_accuracy: 0.9122\n",
            "Epoch 44/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2787 - accuracy: 0.9356 - val_loss: 0.5123 - val_accuracy: 0.9228\n",
            "Epoch 45/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2823 - accuracy: 0.9339 - val_loss: 0.5125 - val_accuracy: 0.9287\n",
            "Epoch 46/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2788 - accuracy: 0.9350 - val_loss: 0.5414 - val_accuracy: 0.9151\n",
            "Epoch 47/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.9328 - val_loss: 0.4981 - val_accuracy: 0.9209\n",
            "Epoch 48/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2754 - accuracy: 0.9361 - val_loss: 0.5424 - val_accuracy: 0.9220\n",
            "Epoch 49/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2884 - accuracy: 0.9323 - val_loss: 0.5387 - val_accuracy: 0.9252\n",
            "Epoch 50/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2769 - accuracy: 0.9363 - val_loss: 0.5286 - val_accuracy: 0.9226\n",
            "Epoch 51/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2748 - accuracy: 0.9372 - val_loss: 0.5198 - val_accuracy: 0.9221\n",
            "Epoch 52/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2859 - accuracy: 0.9323 - val_loss: 0.5335 - val_accuracy: 0.9224\n",
            "Epoch 53/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2915 - accuracy: 0.9316 - val_loss: 0.5138 - val_accuracy: 0.9227\n",
            "Epoch 54/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2919 - accuracy: 0.9296 - val_loss: 0.5592 - val_accuracy: 0.9203\n",
            "Epoch 55/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2856 - accuracy: 0.9349 - val_loss: 0.4959 - val_accuracy: 0.9276\n",
            "Epoch 56/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2918 - accuracy: 0.9323 - val_loss: 0.4761 - val_accuracy: 0.9228\n",
            "Epoch 57/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2821 - accuracy: 0.9336 - val_loss: 0.5028 - val_accuracy: 0.9206\n",
            "Epoch 58/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2900 - accuracy: 0.9312 - val_loss: 0.5496 - val_accuracy: 0.9196\n",
            "Epoch 59/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2890 - accuracy: 0.9319 - val_loss: 0.5070 - val_accuracy: 0.9186\n",
            "Epoch 60/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3023 - accuracy: 0.9281 - val_loss: 0.5995 - val_accuracy: 0.9089\n",
            "Epoch 61/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2998 - accuracy: 0.9272 - val_loss: 0.5869 - val_accuracy: 0.9108\n",
            "Epoch 62/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.9316 - val_loss: 0.5713 - val_accuracy: 0.9205\n",
            "Epoch 63/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2932 - accuracy: 0.9339 - val_loss: 0.5448 - val_accuracy: 0.9232\n",
            "Epoch 64/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2958 - accuracy: 0.9342 - val_loss: 0.5144 - val_accuracy: 0.9209\n",
            "Epoch 65/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2796 - accuracy: 0.9351 - val_loss: 0.5578 - val_accuracy: 0.9123\n",
            "Epoch 66/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3007 - accuracy: 0.9308 - val_loss: 0.5432 - val_accuracy: 0.9219\n",
            "Epoch 67/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2747 - accuracy: 0.9363 - val_loss: 0.5334 - val_accuracy: 0.9181\n",
            "Epoch 68/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2920 - accuracy: 0.9295 - val_loss: 0.6071 - val_accuracy: 0.9074\n",
            "Epoch 69/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3286 - accuracy: 0.9186 - val_loss: 0.5754 - val_accuracy: 0.9122\n",
            "Epoch 70/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3083 - accuracy: 0.9236 - val_loss: 0.5692 - val_accuracy: 0.9175\n",
            "Epoch 71/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3078 - accuracy: 0.9252 - val_loss: 0.5462 - val_accuracy: 0.9157\n",
            "Epoch 72/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2939 - accuracy: 0.9288 - val_loss: 0.5476 - val_accuracy: 0.9140\n",
            "Epoch 73/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3055 - accuracy: 0.9264 - val_loss: 0.6214 - val_accuracy: 0.9113\n",
            "Epoch 74/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3101 - accuracy: 0.9258 - val_loss: 0.5378 - val_accuracy: 0.9181\n",
            "Epoch 75/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3132 - accuracy: 0.9232 - val_loss: 0.5645 - val_accuracy: 0.9103\n",
            "Epoch 76/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3187 - accuracy: 0.9272 - val_loss: 0.5618 - val_accuracy: 0.9210\n",
            "Epoch 77/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3019 - accuracy: 0.9294 - val_loss: 0.5727 - val_accuracy: 0.9181\n",
            "Epoch 78/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2939 - accuracy: 0.9303 - val_loss: 0.5743 - val_accuracy: 0.9153\n",
            "Epoch 79/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.9296 - val_loss: 0.5570 - val_accuracy: 0.9140\n",
            "Epoch 80/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3001 - accuracy: 0.9284 - val_loss: 0.5709 - val_accuracy: 0.9115\n",
            "Epoch 81/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3144 - accuracy: 0.9241 - val_loss: 0.6449 - val_accuracy: 0.9068\n",
            "Epoch 82/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3018 - accuracy: 0.9270 - val_loss: 0.6354 - val_accuracy: 0.9132\n",
            "Epoch 83/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3261 - accuracy: 0.9186 - val_loss: 0.6662 - val_accuracy: 0.8952\n",
            "Epoch 84/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3448 - accuracy: 0.9111 - val_loss: 0.6614 - val_accuracy: 0.8958\n",
            "Epoch 85/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3152 - accuracy: 0.9208 - val_loss: 0.6895 - val_accuracy: 0.9010\n",
            "Epoch 86/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3364 - accuracy: 0.9162 - val_loss: 0.6352 - val_accuracy: 0.9001\n",
            "Epoch 87/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3117 - accuracy: 0.9252 - val_loss: 0.5780 - val_accuracy: 0.9111\n",
            "Epoch 88/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3100 - accuracy: 0.9213 - val_loss: 0.6619 - val_accuracy: 0.8881\n",
            "Epoch 89/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3181 - accuracy: 0.9231 - val_loss: 0.5712 - val_accuracy: 0.9151\n",
            "Epoch 90/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3173 - accuracy: 0.9222 - val_loss: 0.6347 - val_accuracy: 0.8942\n",
            "Epoch 91/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3244 - accuracy: 0.9224 - val_loss: 0.6501 - val_accuracy: 0.9054\n",
            "Epoch 92/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.9249 - val_loss: 0.7051 - val_accuracy: 0.9086\n",
            "Epoch 93/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3213 - accuracy: 0.9227 - val_loss: 0.6357 - val_accuracy: 0.9131\n",
            "Epoch 94/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3155 - accuracy: 0.9242 - val_loss: 0.6383 - val_accuracy: 0.9131\n",
            "Epoch 95/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3147 - accuracy: 0.9207 - val_loss: 0.6596 - val_accuracy: 0.9043\n",
            "Epoch 96/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3207 - accuracy: 0.9225 - val_loss: 0.6304 - val_accuracy: 0.9118\n",
            "Epoch 97/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3356 - accuracy: 0.9138 - val_loss: 0.6670 - val_accuracy: 0.8967\n",
            "Epoch 98/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3393 - accuracy: 0.9128 - val_loss: 0.6678 - val_accuracy: 0.8959\n",
            "Epoch 99/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3463 - accuracy: 0.9122 - val_loss: 0.6422 - val_accuracy: 0.9065\n",
            "Epoch 100/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3248 - accuracy: 0.9197 - val_loss: 0.6314 - val_accuracy: 0.9074\n",
            "Epoch 101/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3248 - accuracy: 0.9201 - val_loss: 0.6304 - val_accuracy: 0.9016\n",
            "Epoch 102/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3263 - accuracy: 0.9202 - val_loss: 0.6680 - val_accuracy: 0.9016\n",
            "Epoch 103/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3272 - accuracy: 0.9196 - val_loss: 0.7269 - val_accuracy: 0.9063\n",
            "Epoch 104/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3610 - accuracy: 0.9033 - val_loss: 0.6566 - val_accuracy: 0.9000\n",
            "Epoch 105/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3407 - accuracy: 0.9094 - val_loss: 0.7162 - val_accuracy: 0.8901\n",
            "Epoch 106/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3639 - accuracy: 0.9031 - val_loss: 0.7498 - val_accuracy: 0.9016\n",
            "Epoch 107/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3404 - accuracy: 0.9137 - val_loss: 0.7229 - val_accuracy: 0.9099\n",
            "Epoch 108/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3469 - accuracy: 0.9154 - val_loss: 0.9020 - val_accuracy: 0.8710\n",
            "Epoch 109/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3362 - accuracy: 0.9160 - val_loss: 0.7429 - val_accuracy: 0.9074\n",
            "Epoch 110/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3368 - accuracy: 0.9147 - val_loss: 0.7692 - val_accuracy: 0.8997\n",
            "Epoch 111/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3467 - accuracy: 0.9083 - val_loss: 0.7390 - val_accuracy: 0.8860\n",
            "Epoch 112/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3613 - accuracy: 0.9002 - val_loss: 0.6911 - val_accuracy: 0.8938\n",
            "Epoch 113/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3617 - accuracy: 0.9004 - val_loss: 0.7523 - val_accuracy: 0.8977\n",
            "Epoch 114/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3554 - accuracy: 0.9079 - val_loss: 0.7283 - val_accuracy: 0.8913\n",
            "Epoch 115/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3621 - accuracy: 0.9073 - val_loss: 0.7267 - val_accuracy: 0.9048\n",
            "Epoch 116/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3360 - accuracy: 0.9134 - val_loss: 0.6986 - val_accuracy: 0.8846\n",
            "Epoch 117/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3492 - accuracy: 0.9095 - val_loss: 0.6656 - val_accuracy: 0.9013\n",
            "Epoch 118/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3365 - accuracy: 0.9149 - val_loss: 0.6582 - val_accuracy: 0.9027\n",
            "Epoch 119/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3321 - accuracy: 0.9156 - val_loss: 0.7039 - val_accuracy: 0.8994\n",
            "Epoch 120/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3548 - accuracy: 0.9080 - val_loss: 0.7603 - val_accuracy: 0.8999\n",
            "Epoch 121/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3491 - accuracy: 0.9083 - val_loss: 0.7283 - val_accuracy: 0.8876\n",
            "Epoch 122/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3635 - accuracy: 0.9049 - val_loss: 0.6871 - val_accuracy: 0.8929\n",
            "Epoch 123/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3641 - accuracy: 0.9030 - val_loss: 0.7592 - val_accuracy: 0.8919\n",
            "Epoch 124/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3601 - accuracy: 0.9007 - val_loss: 0.7496 - val_accuracy: 0.8818\n",
            "Epoch 125/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3551 - accuracy: 0.9022 - val_loss: 0.7586 - val_accuracy: 0.8879\n",
            "Epoch 126/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3689 - accuracy: 0.8991 - val_loss: 0.7395 - val_accuracy: 0.8710\n",
            "Epoch 127/200\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3601 - accuracy: 0.9020 - val_loss: 0.7660 - val_accuracy: 0.8817\n",
            "Epoch 128/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3938 - accuracy: 0.8881 - val_loss: 0.7147 - val_accuracy: 0.8683\n",
            "Epoch 129/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4053 - accuracy: 0.8845 - val_loss: 0.7546 - val_accuracy: 0.8740\n",
            "Epoch 130/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3786 - accuracy: 0.9018 - val_loss: 0.7249 - val_accuracy: 0.8981\n",
            "Epoch 131/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3470 - accuracy: 0.9114 - val_loss: 0.7154 - val_accuracy: 0.8976\n",
            "Epoch 132/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3496 - accuracy: 0.9077 - val_loss: 0.9714 - val_accuracy: 0.8832\n",
            "Epoch 133/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3870 - accuracy: 0.8968 - val_loss: 0.7259 - val_accuracy: 0.8886\n",
            "Epoch 134/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3672 - accuracy: 0.9036 - val_loss: 0.7370 - val_accuracy: 0.8934\n",
            "Epoch 135/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3771 - accuracy: 0.9015 - val_loss: 0.7483 - val_accuracy: 0.8920\n",
            "Epoch 136/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3648 - accuracy: 0.9082 - val_loss: 0.7490 - val_accuracy: 0.8998\n",
            "Epoch 137/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3457 - accuracy: 0.9109 - val_loss: 0.7344 - val_accuracy: 0.8895\n",
            "Epoch 138/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3591 - accuracy: 0.9079 - val_loss: 0.7429 - val_accuracy: 0.8950\n",
            "Epoch 139/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3595 - accuracy: 0.9036 - val_loss: 0.7879 - val_accuracy: 0.8932\n",
            "Epoch 140/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3637 - accuracy: 0.9056 - val_loss: 0.8341 - val_accuracy: 0.8790\n",
            "Epoch 141/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3665 - accuracy: 0.9046 - val_loss: 0.8088 - val_accuracy: 0.9032\n",
            "Epoch 142/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3678 - accuracy: 0.9074 - val_loss: 0.8119 - val_accuracy: 0.8839\n",
            "Epoch 143/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3485 - accuracy: 0.9142 - val_loss: 0.7174 - val_accuracy: 0.8969\n",
            "Epoch 144/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3495 - accuracy: 0.9150 - val_loss: 0.7815 - val_accuracy: 0.8966\n",
            "Epoch 145/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3548 - accuracy: 0.9080 - val_loss: 0.8018 - val_accuracy: 0.8937\n",
            "Epoch 146/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3817 - accuracy: 0.8987 - val_loss: 0.7709 - val_accuracy: 0.8880\n",
            "Epoch 147/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3790 - accuracy: 0.8997 - val_loss: 0.8152 - val_accuracy: 0.8775\n",
            "Epoch 148/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3801 - accuracy: 0.8943 - val_loss: 0.8052 - val_accuracy: 0.8850\n",
            "Epoch 149/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3782 - accuracy: 0.8946 - val_loss: 0.8536 - val_accuracy: 0.8862\n",
            "Epoch 150/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3762 - accuracy: 0.9022 - val_loss: 0.9075 - val_accuracy: 0.9007\n",
            "Epoch 151/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3632 - accuracy: 0.9051 - val_loss: 0.7790 - val_accuracy: 0.8914\n",
            "Epoch 152/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3748 - accuracy: 0.8969 - val_loss: 0.8540 - val_accuracy: 0.8833\n",
            "Epoch 153/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3789 - accuracy: 0.8960 - val_loss: 0.7735 - val_accuracy: 0.8885\n",
            "Epoch 154/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3864 - accuracy: 0.8893 - val_loss: 0.8940 - val_accuracy: 0.8702\n",
            "Epoch 155/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3890 - accuracy: 0.8906 - val_loss: 0.7872 - val_accuracy: 0.8829\n",
            "Epoch 156/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3999 - accuracy: 0.8834 - val_loss: 0.8154 - val_accuracy: 0.8761\n",
            "Epoch 157/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4114 - accuracy: 0.8792 - val_loss: 0.8267 - val_accuracy: 0.8629\n",
            "Epoch 158/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4141 - accuracy: 0.8830 - val_loss: 0.7721 - val_accuracy: 0.8746\n",
            "Epoch 159/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3801 - accuracy: 0.8939 - val_loss: 0.8770 - val_accuracy: 0.8788\n",
            "Epoch 160/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3932 - accuracy: 0.8947 - val_loss: 0.8250 - val_accuracy: 0.8757\n",
            "Epoch 161/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3790 - accuracy: 0.8916 - val_loss: 0.8481 - val_accuracy: 0.8808\n",
            "Epoch 162/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4166 - accuracy: 0.8762 - val_loss: 0.8168 - val_accuracy: 0.8539\n",
            "Epoch 163/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4596 - accuracy: 0.8635 - val_loss: 0.8237 - val_accuracy: 0.8487\n",
            "Epoch 164/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4299 - accuracy: 0.8666 - val_loss: 0.8716 - val_accuracy: 0.8655\n",
            "Epoch 165/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4063 - accuracy: 0.8823 - val_loss: 0.8360 - val_accuracy: 0.8650\n",
            "Epoch 166/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4077 - accuracy: 0.8777 - val_loss: 0.8263 - val_accuracy: 0.8759\n",
            "Epoch 167/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3996 - accuracy: 0.8838 - val_loss: 0.8515 - val_accuracy: 0.8756\n",
            "Epoch 168/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3866 - accuracy: 0.8962 - val_loss: 0.8906 - val_accuracy: 0.8727\n",
            "Epoch 169/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3849 - accuracy: 0.8913 - val_loss: 0.9004 - val_accuracy: 0.8780\n",
            "Epoch 170/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4017 - accuracy: 0.8879 - val_loss: 0.8992 - val_accuracy: 0.8783\n",
            "Epoch 171/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3924 - accuracy: 0.8930 - val_loss: 0.8536 - val_accuracy: 0.8743\n",
            "Epoch 172/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3958 - accuracy: 0.8889 - val_loss: 0.8905 - val_accuracy: 0.8723\n",
            "Epoch 173/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3960 - accuracy: 0.8907 - val_loss: 0.8343 - val_accuracy: 0.8786\n",
            "Epoch 174/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3951 - accuracy: 0.8923 - val_loss: 0.8105 - val_accuracy: 0.8827\n",
            "Epoch 175/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3839 - accuracy: 0.8982 - val_loss: 0.9227 - val_accuracy: 0.8881\n",
            "Epoch 176/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4187 - accuracy: 0.8856 - val_loss: 0.8244 - val_accuracy: 0.8685\n",
            "Epoch 177/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3957 - accuracy: 0.8904 - val_loss: 0.8744 - val_accuracy: 0.8761\n",
            "Epoch 178/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4096 - accuracy: 0.8852 - val_loss: 0.8175 - val_accuracy: 0.8772\n",
            "Epoch 179/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3798 - accuracy: 0.8970 - val_loss: 0.9325 - val_accuracy: 0.8860\n",
            "Epoch 180/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3903 - accuracy: 0.8875 - val_loss: 0.8647 - val_accuracy: 0.8581\n",
            "Epoch 181/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4606 - accuracy: 0.8555 - val_loss: 0.9483 - val_accuracy: 0.8323\n",
            "Epoch 182/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4535 - accuracy: 0.8593 - val_loss: 1.0296 - val_accuracy: 0.8498\n",
            "Epoch 183/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4423 - accuracy: 0.8710 - val_loss: 0.8676 - val_accuracy: 0.8612\n",
            "Epoch 184/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4310 - accuracy: 0.8798 - val_loss: 0.9525 - val_accuracy: 0.8550\n",
            "Epoch 185/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4224 - accuracy: 0.8816 - val_loss: 1.0057 - val_accuracy: 0.8696\n",
            "Epoch 186/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4160 - accuracy: 0.8812 - val_loss: 0.9636 - val_accuracy: 0.8584\n",
            "Epoch 187/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4490 - accuracy: 0.8714 - val_loss: 0.8544 - val_accuracy: 0.8689\n",
            "Epoch 188/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4204 - accuracy: 0.8846 - val_loss: 0.9626 - val_accuracy: 0.8714\n",
            "Epoch 189/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4099 - accuracy: 0.8890 - val_loss: 1.0005 - val_accuracy: 0.8845\n",
            "Epoch 190/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4096 - accuracy: 0.8886 - val_loss: 0.9628 - val_accuracy: 0.8753\n",
            "Epoch 191/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4092 - accuracy: 0.8817 - val_loss: 0.9737 - val_accuracy: 0.8715\n",
            "Epoch 192/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4165 - accuracy: 0.8818 - val_loss: 1.0156 - val_accuracy: 0.8691\n",
            "Epoch 193/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4098 - accuracy: 0.8848 - val_loss: 0.9643 - val_accuracy: 0.8719\n",
            "Epoch 194/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4027 - accuracy: 0.8836 - val_loss: 0.8973 - val_accuracy: 0.8736\n",
            "Epoch 195/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3955 - accuracy: 0.8862 - val_loss: 0.9633 - val_accuracy: 0.8678\n",
            "Epoch 196/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4169 - accuracy: 0.8799 - val_loss: 0.9614 - val_accuracy: 0.8495\n",
            "Epoch 197/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4151 - accuracy: 0.8760 - val_loss: 0.9741 - val_accuracy: 0.8704\n",
            "Epoch 198/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3947 - accuracy: 0.8829 - val_loss: 1.0253 - val_accuracy: 0.8699\n",
            "Epoch 199/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4276 - accuracy: 0.8685 - val_loss: 1.0266 - val_accuracy: 0.8473\n",
            "Epoch 200/200\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4107 - accuracy: 0.8777 - val_loss: 1.0211 - val_accuracy: 0.8695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f859629abd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWi2aH_gHQxP"
      },
      "source": [
        "#Discriminator\n",
        "img = Input((28,28,1))\n",
        "f1    = Flatten()(img)\n",
        "d1    = Dense(32, activation='LeakyReLU')(f1)\n",
        "d2    = Dense(64, activation='LeakyReLU')(d1)\n",
        "d3    = Dense(32, activation='LeakyReLU')(d2)\n",
        "dis   = Dense(1, activation='sigmoid')(d3)\n",
        "dis = Model(inputs=img, outputs=dis)\n",
        "\n",
        "#Generator\n",
        "noise = Input((100))\n",
        "d1    = Dense(1000, activation='tanh')(noise)\n",
        "d2    = Dense(1000, activation='tanh')(d1)\n",
        "out   = Dense(784 , activation='tanh')(d2)\n",
        "gen   = Reshape((28,28,1))(out)\n",
        "gen = Model(inputs = noise, outputs = gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdTTGkZr1LQ"
      },
      "source": [
        "true = np.ones(x_train.shape[0])\n",
        "false = np.zeros(x_train.shape[0])\n",
        "random_latent_vectors = tf.random.normal(shape=(32, 100))\n",
        "generated_imgs = gen((random_latent_vectors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAWiemUtgxci"
      },
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(32, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNTwV4CFhO1T",
        "outputId": "366cc608-4626-4d5d-e11b-37d5d8db3d68"
      },
      "source": [
        "epochs = 30  # In practice, use ~100 epochs\n",
        "\n",
        "gan = GAN(discriminator=dis, generator=gen, latent_dim=100)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    x_train,epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: 0.1304 - g_loss: 2.2774\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: 0.0047 - g_loss: 5.9326\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -0.0899 - g_loss: 13.9054\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -0.3244 - g_loss: 34.1198\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -0.5505 - g_loss: 53.6335\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -0.6272 - g_loss: 61.3128\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -1.1504 - g_loss: 106.3172\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: -2.6167 - g_loss: 231.0446\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 44s 24ms/step - d_loss: -6.2634 - g_loss: 537.7417\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: -10.8760 - g_loss: 941.8433\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: -20.4005 - g_loss: 1726.2543\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: -35.5421 - g_loss: 3009.2334\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -61.2379 - g_loss: 5141.0908\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -87.0115 - g_loss: 7294.1968\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -153.3796 - g_loss: 12744.6396\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -252.5438 - g_loss: 21160.1836\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 42s 23ms/step - d_loss: -273.9563 - g_loss: 22901.4551\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -454.4271 - g_loss: 37283.2344\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - d_loss: -746.7042 - g_loss: 61334.9805\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -1002.3947 - g_loss: 82534.2109\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - d_loss: -1076.9863 - g_loss: 89373.9688\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -1730.4481 - g_loss: 142402.0625\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -2208.7856 - g_loss: 182254.7969\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -3078.7083 - g_loss: 252846.9688\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -3547.9858 - g_loss: 292476.8750\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -5100.7227 - g_loss: 418616.0938\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 44s 23ms/step - d_loss: -5565.6489 - g_loss: 459423.0625\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -7322.9136 - g_loss: 603025.1875\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 43s 23ms/step - d_loss: -9804.9297 - g_loss: 807762.8750\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 42s 22ms/step - d_loss: -11223.7656 - g_loss: 929566.0625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafa2d9f390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Eiq0sRPmpH",
        "outputId": "696a979f-5450-4c30-f17f-7d0e30eee578"
      },
      "source": [
        "gen.save('/content')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsk1F8x0uo-g"
      },
      "source": [
        "gen(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAAA4MLtvKYC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}